{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define tensors in pytorch - same as arrays in numpy - with tensor\n",
    "X = torch.tensor(([2,9], [1,5], [3,6]), dtype=torch.float) #3x2 tensor\n",
    "y = torch.tensor(([92], [100], [89]), dtype=torch.float) #3 by 1 tensor\n",
    "x_test = torch.tensor(([4, 8]))\n",
    "\n",
    "#can check the size with .size()\n",
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6667, 1.0000],\n",
      "        [0.3333, 0.5556],\n",
      "        [1.0000, 0.6667]])\n"
     ]
    }
   ],
   "source": [
    "#apply scaling\n",
    "#max function returns max element and indice\n",
    "X_max, _ = torch.max(X, 0)\n",
    "xPredicted_max, _ = torch.max(x_test, 0)\n",
    "\n",
    "#divides all the elements by X_max - in this case X_max return largest single value in the matrices i.e. 9\n",
    "X = torch.div(X, X_max)\n",
    "x_test = torch.div(x_test, xPredicted_max)\n",
    "y = y/100\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building The Neural Network\n",
    "#nn.module is the base class for any module in PyTorch\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenNodes = 3\n",
    "        \n",
    "        self.W1 = torch.randn(self.inputSize, self.hiddenNodes) #Tensor is 2 by 3 since (1 by 2) * (2 by 3) gives desired (1 by 3)\n",
    "        self.W2 = torch.randn(self.hiddenNodes, self.outputSize) #Tesnsor is 3 by 1\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.z = torch.matmul(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3)\n",
    "        return o\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1-s)\n",
    "    \n",
    "    def backward(self, x, y, o):\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        #torch.t is the transpose operation\n",
    "        #recall in the second wave of operations we do sigmoid(z2 * W2)\n",
    "        #thus this can be represented as two nodes in a computation graph, the sigmoid and the matrix multiplication\n",
    "        #partial derivative at the matrix multiplication level\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        #partial derivative at the sigmoid level\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
    "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
    "    \n",
    "         \n",
    "    def train(self, X, y):\n",
    "        # forward + backward pass for training\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "    def saveWeights(self, model):\n",
    "        # we will use the PyTorch internal storage functions\n",
    "        torch.save(model, \"NN\")\n",
    "        # you can reload model with all the weights and so forth with:\n",
    "        # torch.load(\"NN\")\n",
    "        \n",
    "    def predict(self):\n",
    "        print (\"Predicted data based on trained weights: \")\n",
    "        print (\"Input (scaled): \\n\" + str(x_test))\n",
    "        print (\"Output: \\n\" + str(self.forward(x_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.005908905062824488\n",
      "#1 Loss: 0.005748603492975235\n",
      "#2 Loss: 0.005600081756711006\n",
      "#3 Loss: 0.005462279077619314\n",
      "#4 Loss: 0.005334220826625824\n",
      "#5 Loss: 0.005215070676058531\n",
      "#6 Loss: 0.005104073788970709\n",
      "#7 Loss: 0.005000508856028318\n",
      "#8 Loss: 0.004903781693428755\n",
      "#9 Loss: 0.00481331767514348\n",
      "#10 Loss: 0.004728619009256363\n",
      "#11 Loss: 0.004649232141673565\n",
      "#12 Loss: 0.004574731923639774\n",
      "#13 Loss: 0.004504744429141283\n",
      "#14 Loss: 0.004438930191099644\n",
      "#15 Loss: 0.004376981407403946\n",
      "#16 Loss: 0.0043186102993786335\n",
      "#17 Loss: 0.004263560753315687\n",
      "#18 Loss: 0.004211593884974718\n",
      "#19 Loss: 0.0041624936275184155\n",
      "#20 Loss: 0.0041160574182868\n",
      "#21 Loss: 0.004072108771651983\n",
      "#22 Loss: 0.0040304833091795444\n",
      "#23 Loss: 0.0039910185150802135\n",
      "#24 Loss: 0.003953570034354925\n",
      "#25 Loss: 0.0039180186577141285\n",
      "#26 Loss: 0.0038842360954731703\n",
      "#27 Loss: 0.003852112917229533\n",
      "#28 Loss: 0.0038215413223952055\n",
      "#29 Loss: 0.0037924284115433693\n",
      "#30 Loss: 0.0037646889686584473\n",
      "#31 Loss: 0.003738240571692586\n",
      "#32 Loss: 0.0037130031269043684\n",
      "#33 Loss: 0.00368890562094748\n",
      "#34 Loss: 0.00366588425822556\n",
      "#35 Loss: 0.0036438724491745234\n",
      "#36 Loss: 0.0036228231620043516\n",
      "#37 Loss: 0.0036026735324412584\n",
      "#38 Loss: 0.003583379089832306\n",
      "#39 Loss: 0.0035648879129439592\n",
      "#40 Loss: 0.003547160653397441\n",
      "#41 Loss: 0.0035301547031849623\n",
      "#42 Loss: 0.0035138309467583895\n",
      "#43 Loss: 0.0034981491044163704\n",
      "#44 Loss: 0.0034830865915864706\n",
      "#45 Loss: 0.003468606388196349\n",
      "#46 Loss: 0.003454681485891342\n",
      "#47 Loss: 0.003441267879679799\n",
      "#48 Loss: 0.003428364871069789\n",
      "#49 Loss: 0.0034159335773438215\n",
      "#50 Loss: 0.0034039488527923822\n",
      "#51 Loss: 0.0033923909068107605\n",
      "#52 Loss: 0.003381244605407119\n",
      "#53 Loss: 0.0033704868983477354\n",
      "#54 Loss: 0.0033600961323827505\n",
      "#55 Loss: 0.0033500539138913155\n",
      "#56 Loss: 0.003340350463986397\n",
      "#57 Loss: 0.0033309769351035357\n",
      "#58 Loss: 0.003321899101138115\n",
      "#59 Loss: 0.003313114633783698\n",
      "#60 Loss: 0.0033046144526451826\n",
      "#61 Loss: 0.003296372713521123\n",
      "#62 Loss: 0.0032883917447179556\n",
      "#63 Loss: 0.0032806468661874533\n",
      "#64 Loss: 0.003273141337558627\n",
      "#65 Loss: 0.003265855135396123\n",
      "#66 Loss: 0.003258781274780631\n",
      "#67 Loss: 0.0032519102096557617\n",
      "#68 Loss: 0.0032452300656586885\n",
      "#69 Loss: 0.0032387457322329283\n",
      "#70 Loss: 0.003232440212741494\n",
      "#71 Loss: 0.0032263007014989853\n",
      "#72 Loss: 0.003220325568690896\n",
      "#73 Loss: 0.0032145120203495026\n",
      "#74 Loss: 0.0032088449224829674\n",
      "#75 Loss: 0.003203330561518669\n",
      "#76 Loss: 0.003197945887222886\n",
      "#77 Loss: 0.00319269928149879\n",
      "#78 Loss: 0.0031875865533947945\n",
      "#79 Loss: 0.0031825918704271317\n",
      "#80 Loss: 0.0031777098774909973\n",
      "#81 Loss: 0.003172951517626643\n",
      "#82 Loss: 0.0031682963017374277\n",
      "#83 Loss: 0.003163750981912017\n",
      "#84 Loss: 0.003159303218126297\n",
      "#85 Loss: 0.003154949052259326\n",
      "#86 Loss: 0.003150690346956253\n",
      "#87 Loss: 0.00314652849920094\n",
      "#88 Loss: 0.003142450237646699\n",
      "#89 Loss: 0.0031384516041725874\n",
      "#90 Loss: 0.003134535625576973\n",
      "#91 Loss: 0.0031306936871260405\n",
      "#92 Loss: 0.003126931143924594\n",
      "#93 Loss: 0.0031232377514243126\n",
      "#94 Loss: 0.0031196093186736107\n",
      "#95 Loss: 0.003116052597761154\n",
      "#96 Loss: 0.0031125580426305532\n",
      "#97 Loss: 0.003109130309894681\n",
      "#98 Loss: 0.0031057533342391253\n",
      "#99 Loss: 0.003102437360212207\n",
      "Predicted data based on trained weights: \n",
      "Input (scaled): \n",
      "tensor([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NeuralNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'mat2' in call to _th_mm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c4d265fc4b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-818c171fd3a0>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted data based on trained weights: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Input (scaled): \\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Output: \\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-818c171fd3a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'mat2' in call to _th_mm"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "NN = NeuralNetwork()\n",
    "for i in range(100):\n",
    "    #NN(X) automatically calls the forward so there is no need to explicity call forward\n",
    "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
    "    NN.train(X, y)\n",
    "NN.saveWeights(NN)\n",
    "NN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
